{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd # Pandas library\n",
    "import numpy as np # Numpy library\n",
    "import matplotlib.pyplot as plt # Matplotlib library\n",
    "import numpy.linalg as la # Linear algebra functions\n",
    "import math # Math library\n",
    "import random # Random library\n",
    "import seaborn as sns # Seaborn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "A \"from-scratch\" neural network implementation for educational purposes.\n",
    "This version is a simple binary classififer. It allows the user to incrementally\n",
    "train the network, displaying the resulting decision boundary and full density.\n",
    "The training data is hard-coded, but there is also a loop to allow more\n",
    "custom training data. We initialize the weights to be drawn from a standard\n",
    "Gaussian distribution.\n",
    "\n",
    "A crude diagram of a NN with two hidden layers and 2-dimensional inputs.\n",
    "The final layer is returned as a weighted sum, passed through a final\n",
    "sigmoid function. This scalar will determine which class to assign to the\n",
    "input point.\n",
    "\n",
    "x1--O---O\n",
    "  \\ / \\ / \\ \n",
    "   x   x   O --\n",
    "  / \\ / \\ /\n",
    "x2--O---O\n",
    "\n",
    "@author: Joseph Anderson <jtanderson@salisbury.edu>\n",
    "@date:   28 May 2019\n",
    "\n",
    "Exercise 1: vectorize more of the operations, combine the input, output, and\n",
    "hidden layers into single matrices. \n",
    "Exercise 2: Adapt the model to learn more than two classes\n",
    "Exercise 3: Use \"convolutional\" or \"recurrent\" neuron architectures\n",
    "Exercise 4: Turn into a \"generative\" model, to generate typical examples\n",
    "from either of the two classes\n",
    "Exercise 5: Parallelize!\n",
    "\n",
    "\n",
    "For motivation/explanation, see, for example:\n",
    "https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/\n",
    "\"\"\"\n",
    "\n",
    "# The dimensionality of the input data\n",
    "dim = 6\n",
    "\n",
    "# The number of hidden layers\n",
    "num_layers = 1\n",
    "\n",
    "# The size of each hidden layer\n",
    "layer_size = 2\n",
    "\n",
    "# The step size used in gradient descent\n",
    "rate = 0.1\n",
    "\n",
    "bias = True\n",
    "\n",
    "# add a dimension for bias\n",
    "if bias:\n",
    "    dim += 1\n",
    "\n",
    "# X holds N-by-d samples\n",
    "#   - N is number of samples\n",
    "#   - d is dimension\n",
    "X = np.empty((0,dim), float)\n",
    "\n",
    "# Y holds N labels of -1 or 1\n",
    "Y = np.array([])\n",
    "\n",
    "# input weights. Row i is the array of weights applied to x_i\n",
    "w_in = np.random.standard_normal((dim,layer_size))\n",
    "\n",
    "# \"Tensor\" (3-dim array) of hidden-layer output weights. \n",
    "# w_hidden[lay][i][j] is the weight between lay node i and lay+1 node j\n",
    "w_hidden = np.random.standard_normal((num_layers-1, layer_size, layer_size))\n",
    "\n",
    "# output weights, comes from last layer\n",
    "w_out = np.random.standard_normal((1,layer_size))\n",
    "\n",
    "# Use the standard sigmoid function. Another option is arctan, etc.\n",
    "def sigmoid(arr):\n",
    "    return 1/(1+np.exp(-1*arr))\n",
    "\n",
    "# The derivative of the sigmoid function.\n",
    "# Check this by hand to see how convenient it is :)\n",
    "def sigmoid_deriv(arr):\n",
    "    return sigmoid(arr) * (1 - sigmoid(arr))\n",
    "\n",
    "# The squared error between to vectors/scalars\n",
    "def msqerr(pred, ans):\n",
    "    return np.sum((pred-ans)**2)/2\n",
    "\n",
    "def reset():\n",
    "    w_in = np.random.standard_normal((dim,layer_size))\n",
    "    w_hidden = np.random.standard_normal((num_layers-1, layer_size, layer_size))\n",
    "    w_out = np.random.standard_normal((1,layer_size))\n",
    "    return (w_in, w_hidden, w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward_step takes the weights of the network and an input point,\n",
    "returning the scalar output of the network, along with a matrix\n",
    "which is a record of the output of each intermediate node during\n",
    "the computation. This is needed for training and verification.\n",
    "\n",
    "Arguments:\n",
    "inw is the dim-by-h matrix of input weights to the first layer\n",
    "outw is the h-by-1 array of weights from the last hidden layer to the output node\n",
    "hiddenw is the num_layers-by-layer_size-by-layer_size matrix of weights between each layer\n",
    "    hidden[i] has the weights from i to i+1\n",
    "    hidden[i][j] is the array of weights into node j of layer i+1\n",
    "data is 1-by-dim row vector\n",
    "\n",
    "Returns:\n",
    "scalar value coming out of the output node\n",
    "outs is layers-by-layer_size to store the output of each node\n",
    "\"\"\"\n",
    "def forward_step(inw, outw, hiddenw, data):\n",
    "    outs = np.array([sigmoid(data @ inw)]) # 1-by-dim times dim-by-h\n",
    "    for i in range(1,num_layers):\n",
    "        # i-1 here because w[i] is output weights\n",
    "        # get the output of the last layer (sig of x) and weight it into this layer\n",
    "        ins = outs[-1] @ hiddenw[i-1]  # 1-by-h times h-by-h\n",
    "        outs = np.append(outs, [sigmoid(ins)], axis=0)\n",
    "\n",
    "    # last row of outs now holds the weighted output of the last hidden layer\n",
    "    ret = sigmoid(outs[-1] @ outw.T)\n",
    "    return ret[0], outs\n",
    "\n",
    "\"\"\"\n",
    "backprop analyzes how wrong the network was at predicting a given label,\n",
    "then uses the magnitude of the error to perform gradient descent on the\n",
    "edge weights throughout the network. Check this with the chain rule\n",
    "of the error function! It tracks the change in error with respect to weights,\n",
    "inputs, and outputs of every node in the network\n",
    "\n",
    "inw: dim-by-layer_size\n",
    "    weights of the input nodes\n",
    "outw: 1-by-layer_size\n",
    "    weights to the output node\n",
    "hiddenw: num_layers-1 x layer_size x layer_size\n",
    "    hiddenw[lay][i][j] is the weight between lay node i and lay+1 node j\n",
    "    a column is all input weights to that node\n",
    "outputs: num_layers x layer_size\n",
    "    record of every node's output from the forward pass\n",
    "pred: scalar predicted output\n",
    "data: the input data point\n",
    "label: scalar true output\n",
    "\"\"\"\n",
    "def backprop(inw, outw, hiddenw, outputs, pred, data, label):\n",
    "    dEyo = pred - label # scalar\n",
    "    dExo = dEyo * sigmoid_deriv(np.dot(outputs[-1], outw[0])) # scalar\n",
    "    dEwo =  dExo * outputs[-1] #np.zeros((1, layer_size)) # out\n",
    "    \n",
    "    # hidden layer derivatives setup\n",
    "    dEwh = np.zeros((num_layers-1, layer_size, layer_size))\n",
    "    dExh = np.zeros((num_layers, layer_size))\n",
    "    dEyh = np.zeros((num_layers, layer_size))\n",
    "    \n",
    "    # need to do output layer first, not a matrix product\n",
    "    dEyh[-1] = outw * dExo # 1-by-h times scalar\n",
    "\n",
    "    for i in range(num_layers-2,-1,-1):\n",
    "        # i-1 to get the inputs to layer i\n",
    "        x = outputs[i-1] @ hiddenw[i-1] # 1-by-h times h-by-h\n",
    "        dExh[i] = dEyh[i] * sigmoid_deriv(x) # 1-by-h\n",
    "        dEwh[i] = outputs[i-1] * dExh[i]\n",
    "        if i > 0:\n",
    "            # prep the next layer\n",
    "            dEyh[i-1] = hiddenw[i] @ dExh[i].T # h-by-h times h-by-1\n",
    "\n",
    "    #dEwi = outputs[0] * dEyh[0] # take care of the input layer, again\n",
    "                                # not a matrix product\n",
    "    data = numpy.array([data])\n",
    "    dEwi = np.matlib.repmat(data.T, 1, layer_size) * np.matlib.repmat(dExh[0], dim, 1)  # dim-by-h broadcast dim-by-h\n",
    "\n",
    "\n",
    "    # adjust the hiden layer weights accoriding to the error.\n",
    "    # Check to see that this follows gradient descent!\n",
    "    hiddenw = hiddenw - rate * dEwh\n",
    "    inw = inw - rate * dEwi\n",
    "    outw[0] = outw[0] - rate * dEwo\n",
    "\n",
    "    # return the new weights\n",
    "    return inw, outw, hiddenw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rounds(train_x, train_y, num_rounds, w_in, w_out, w_hidden):    \n",
    "    # iterate as long as we're told\n",
    "    # For each epoch, it would be helpful to print the total \"loss\" -- the error\n",
    "    # across the whole training set.\n",
    "    # Often, one might choose a loss threshold (say, < 0.0001) and simply train until\n",
    "    # the loss is smaller\n",
    "    for i in range(1,num_rounds+1):\n",
    "        print(f\"Itteration i: {i}\")\n",
    "        # iterate each data point\n",
    "        loss = 0\n",
    "        for j in range(0,train_x.shape[0]):\n",
    "            dat = train_x[j]\n",
    "            if bias:\n",
    "                dat = np.append(train_x[j], [1])\n",
    "\n",
    "            # get the prediction for the point, using the current weights (model)\n",
    "            pred, vals = forward_step(w_in, w_out, w_hidden, dat)\n",
    "            # adjust the weights (model) to account for whether we're incorrect\n",
    "            w_in, w_out, w_hidden = backprop(w_in, w_out, w_hidden, vals, pred, dat, train_y[j])\n",
    "            loss += abs(pred - train_y[j])**2\n",
    "    print(\"Current loss: \" + str(loss))\n",
    "\n",
    "    return (w_in, w_out, w_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "crime_data = pd.read_csv('./SanFranciscoCrimeDataset/crime.csv',\n",
    "                          header=1,\n",
    "                          skipinitialspace=False,\n",
    "                          names=['IncidntNum', 'Category', 'Descript', 'DayOfWeek', 'Date', 'Time',\n",
    "                                'PdDistrict', 'Resolution', 'Address', 'X', 'Y', 'Location', 'PdId'])\n",
    "crime_data = crime_data[ ~crime_data['PdDistrict'].isna() ]\n",
    "\n",
    "#Time\n",
    "crime_data_timeMin = [((int(i.split(':')[0])*60) + int(i.split(':')[1])) for i in crime_data['Time']]\n",
    "crime_data['Time in Min'] = crime_data_timeMin\n",
    "\n",
    "#Date\n",
    "crime_data_date = [i.split()[0] for i in crime_data['Date']]\n",
    "crime_data_dateDays = [ ((int(i.split('/')[0])-1)*30.4167) + (int(i.split('/')[1])) for i in crime_data_date]\n",
    "crime_data['Date in Days'] = crime_data_dateDays\n",
    "\n",
    "#PD District\n",
    "District_Parse = list(set([i[0] for i in crime_data[['PdDistrict']].values]))\n",
    "crime_district_mapping = {crime: ind for ind, crime in enumerate(District_Parse)}\n",
    "crime_data_District = [crime_district_mapping[row[1][0]] for row in crime_data[['PdDistrict']].iterrows()]\n",
    "\n",
    "crime_data['One Hot Encoding PdDist'] = crime_data_District\n",
    "\n",
    "#Day of week\n",
    "Day_Parse = list(set([i[0] for i in crime_data[['DayOfWeek']].values]))\n",
    "crime_days_mapping = {crime: ind for ind, crime in enumerate(Day_Parse)}\n",
    "crime_data_Days = [crime_days_mapping[row[1][0]] for row in crime_data[['DayOfWeek']].iterrows()]\n",
    "\n",
    "crime_data['One Hot Encoding DayOfWeek'] = crime_data_Days\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidntNum</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Location</th>\n",
       "      <th>PdId</th>\n",
       "      <th>Time in Min</th>\n",
       "      <th>Date in Days</th>\n",
       "      <th>One Hot Encoding PdDist</th>\n",
       "      <th>One Hot Encoding DayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120058272</td>\n",
       "      <td>WEAPON LAWS</td>\n",
       "      <td>FIREARM, LOADED, IN VEHICLE, POSSESSION OR USE</td>\n",
       "      <td>Friday</td>\n",
       "      <td>01/29/2016 12:00:00 AM</td>\n",
       "      <td>11:00</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>800 Block of BRYANT ST</td>\n",
       "      <td>-122.403405</td>\n",
       "      <td>37.775421</td>\n",
       "      <td>(37.775420706711, -122.403404791479)</td>\n",
       "      <td>12005827212168</td>\n",
       "      <td>660</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141059263</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Monday</td>\n",
       "      <td>04/25/2016 12:00:00 AM</td>\n",
       "      <td>14:59</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>KEITH ST / SHAFTER AV</td>\n",
       "      <td>-122.388856</td>\n",
       "      <td>37.729981</td>\n",
       "      <td>(37.7299809672996, -122.388856204292)</td>\n",
       "      <td>14105926363010</td>\n",
       "      <td>899</td>\n",
       "      <td>116.2501</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160013662</td>\n",
       "      <td>NON-CRIMINAL</td>\n",
       "      <td>LOST PROPERTY</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>01/05/2016 12:00:00 AM</td>\n",
       "      <td>23:50</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>JONES ST / OFARRELL ST</td>\n",
       "      <td>-122.412971</td>\n",
       "      <td>37.785788</td>\n",
       "      <td>(37.7857883766888, -122.412970537591)</td>\n",
       "      <td>16001366271000</td>\n",
       "      <td>1430</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160002740</td>\n",
       "      <td>NON-CRIMINAL</td>\n",
       "      <td>LOST PROPERTY</td>\n",
       "      <td>Friday</td>\n",
       "      <td>01/01/2016 12:00:00 AM</td>\n",
       "      <td>00:30</td>\n",
       "      <td>MISSION</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16TH ST / MISSION ST</td>\n",
       "      <td>-122.419672</td>\n",
       "      <td>37.765050</td>\n",
       "      <td>(37.7650501214668, -122.419671780296)</td>\n",
       "      <td>16000274071000</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160002869</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>Friday</td>\n",
       "      <td>01/01/2016 12:00:00 AM</td>\n",
       "      <td>21:35</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1700 Block of BUSH ST</td>\n",
       "      <td>-122.426077</td>\n",
       "      <td>37.788019</td>\n",
       "      <td>(37.788018555829, -122.426077177375)</td>\n",
       "      <td>16000286904134</td>\n",
       "      <td>1295</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IncidntNum      Category                                        Descript  \\\n",
       "0   120058272   WEAPON LAWS  FIREARM, LOADED, IN VEHICLE, POSSESSION OR USE   \n",
       "1   141059263      WARRANTS                                  WARRANT ARREST   \n",
       "2   160013662  NON-CRIMINAL                                   LOST PROPERTY   \n",
       "3   160002740  NON-CRIMINAL                                   LOST PROPERTY   \n",
       "4   160002869       ASSAULT                                         BATTERY   \n",
       "\n",
       "  DayOfWeek                    Date   Time  PdDistrict      Resolution  \\\n",
       "0    Friday  01/29/2016 12:00:00 AM  11:00    SOUTHERN  ARREST, BOOKED   \n",
       "1    Monday  04/25/2016 12:00:00 AM  14:59     BAYVIEW  ARREST, BOOKED   \n",
       "2   Tuesday  01/05/2016 12:00:00 AM  23:50  TENDERLOIN            NONE   \n",
       "3    Friday  01/01/2016 12:00:00 AM  00:30     MISSION            NONE   \n",
       "4    Friday  01/01/2016 12:00:00 AM  21:35    NORTHERN            NONE   \n",
       "\n",
       "                  Address           X          Y  \\\n",
       "0  800 Block of BRYANT ST -122.403405  37.775421   \n",
       "1   KEITH ST / SHAFTER AV -122.388856  37.729981   \n",
       "2  JONES ST / OFARRELL ST -122.412971  37.785788   \n",
       "3    16TH ST / MISSION ST -122.419672  37.765050   \n",
       "4   1700 Block of BUSH ST -122.426077  37.788019   \n",
       "\n",
       "                                Location            PdId  Time in Min  \\\n",
       "0   (37.775420706711, -122.403404791479)  12005827212168          660   \n",
       "1  (37.7299809672996, -122.388856204292)  14105926363010          899   \n",
       "2  (37.7857883766888, -122.412970537591)  16001366271000         1430   \n",
       "3  (37.7650501214668, -122.419671780296)  16000274071000           30   \n",
       "4   (37.788018555829, -122.426077177375)  16000286904134         1295   \n",
       "\n",
       "   Date in Days  One Hot Encoding PdDist  One Hot Encoding DayOfWeek  \n",
       "0       29.0000                        5                           3  \n",
       "1      116.2501                        8                           5  \n",
       "2        5.0000                        9                           6  \n",
       "3        1.0000                        7                           3  \n",
       "4        1.0000                        0                           3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -122.40340479    37.77542071   660.            29.             5.             3.        ]\n",
      " [ -122.3888562     37.72998097   899.           116.2501         8.             5.        ]\n",
      " [ -122.41297054    37.78578838  1430.             5.             9.             6.        ]\n",
      " ..., \n",
      " [ -122.41226909    37.79067276  1200.           363.5837         4.             4.        ]\n",
      " [ -122.40665871    37.78827453   600.           364.5837         4.             3.        ]\n",
      " [ -122.40340479    37.77542071   840.           336.5837         5.             3.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Input data, linearly separable classes\n",
    "# Even for this setup, the network can have a tough time getting a good model!\n",
    "# Sometimes you can even hit a \"local\" minimum where more training doesn't help,\n",
    "# we need to perturb things a bit or get more data.\n",
    "X = crime_data[['X', 'Y', 'Time in Min', 'Date in Days', 'One Hot Encoding PdDist', 'One Hot Encoding DayOfWeek']].values\n",
    "print(X)\n",
    "# The labels\n",
    "parse_crimes = list(set([i[0] for i in crime_data[['Category']].values]))\n",
    "crime_mapping = {crime: ind for ind, crime in enumerate(parse_crimes)}\n",
    "\n",
    "Y = [crime_mapping[row[1][0]] for row in crime_data[['Category']].iterrows()]\n",
    "epochs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.22431046e+02   3.77830296e+01   1.23000000e+03   1.10250100e+02\n",
      "    0.00000000e+00   6.00000000e+00]\n",
      " [ -1.22403285e+02   3.77873064e+01   3.80000000e+02   4.84167000e+01\n",
      "    5.00000000e+00   4.00000000e+00]\n",
      " [ -1.22381694e+02   3.77278047e+01   1.06500000e+03   2.59333600e+02\n",
      "    8.00000000e+00   3.00000000e+00]\n",
      " ..., \n",
      " [ -1.22444302e+02   3.77903247e+01   9.60000000e+02   3.27167000e+02\n",
      "    2.00000000e+00   1.00000000e+00]\n",
      " [ -1.22435977e+02   3.77231288e+01   6.13000000e+02   2.48333600e+02\n",
      "    6.00000000e+00   5.00000000e+00]\n",
      " [ -1.22403966e+02   3.78000811e+01   1.14000000e+03   1.00250100e+02\n",
      "    4.00000000e+00   2.00000000e+00]]\n",
      "['LARCENY/THEFT' 'NON-CRIMINAL' 'OTHER OFFENSES' ..., 'VEHICLE THEFT'\n",
      " 'WARRANTS' 'LARCENY/THEFT']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def split_sets(dataframe, train_p):\n",
    "    \"\"\"\n",
    "    Returns 2 lists of the form needed to use the KNN class using the San Francisco Crime dataset\n",
    "    -- The function uses x and y coordinate data for graphing and the type of crime as our labels.\n",
    "    **The dataframe passed can be subset to go by location to see how KNN works on each \"area\"\n",
    "    \"\"\"\n",
    "    assert(train_p < 1) # Make sure that p is a percentage\n",
    "    assert(train_p > 0) # Make sure that p is non-negative\n",
    "    \n",
    "    # Split dataframe into training and test/prediction sets\n",
    "    train_count = int(dataframe.shape[0] * train_p)\n",
    "    predict_count = int(dataframe.shape[0] * (1 - train_p))\n",
    "    train_count_Y = int(dataframe.shape[0] * train_p)\n",
    "    predict_count_Y = int(dataframe.shape[0] * (1 - train_p))\n",
    "    \n",
    "    \n",
    "    tmp_list = dataframe.values[:]\n",
    "    np.random.shuffle(tmp_list) # Shuffle the rows\n",
    "    train_list = tmp_list[0:train_count] # Take the first train_p percentage for the training data\n",
    "    predict_list = tmp_list[train_count:] # The rest go to predict data\n",
    "    \n",
    "\n",
    "    rtn_train = [(i[9], i[10], i[13], i[14], i[15], i[16]) for i in train_list]\n",
    "    rtn_predict = [(i[9], i[10], i[13], i[14], i[15], i[16]) for i in predict_list]\n",
    "    \n",
    "    rtn_train_Y = [(i[1]) for i in train_list]\n",
    "    rtn_predict_Y = [(i[1]) for i in predict_list]\n",
    "    \n",
    "    return rtn_train, rtn_predict, rtn_train_Y, rtn_predict_Y\n",
    "\n",
    "\n",
    "train_NN1, predict_NN1, train_NN1_Y, predict_NN1_Y = split_sets(crime_data, .3)\n",
    "\n",
    "train_NN = np.array(train_NN1)\n",
    "train_NN_Y = np.array(train_NN1_Y)\n",
    "\n",
    "print(train_NN)\n",
    "print(train_NN_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_in, w_hidden, w_out = reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itteration i: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:76: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-da8b886fc0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_NN_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-033dcd9408b2>\u001b[0m in \u001b[0;36mtrain_rounds\u001b[0;34m(train_x, train_y, num_rounds, w_in, w_out, w_hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# adjust the weights (model) to account for whether we're incorrect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mw_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2d9b1bd72478>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(inw, outw, hiddenw, outputs, pred, data, label)\u001b[0m\n\u001b[1;32m     50\u001b[0m \"\"\"\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddenw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mdEyo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;31m# scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdExo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdEyo\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigmoid_deriv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdEwo\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdExo\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#np.zeros((1, layer_size)) # out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "w_in, w_out, w_hidden = train_rounds(train_NN, train_NN_Y, 1, w_in, w_out, w_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_in, w_out, w_hidden = train_rounds(X, Y, 10, w_in, w_out, w_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
