{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd # Pandas library\n",
    "import numpy as np # Numpy library\n",
    "import matplotlib.pyplot as plt # Matplotlib library\n",
    "import numpy.linalg as la # Linear algebra functions\n",
    "import math # Math library\n",
    "import random # Random library\n",
    "import seaborn as sns # Seaborn library\n",
    "crime_data = pd.read_csv('../SanFranciscoCrimeDataset/crime.csv',\n",
    "                          header=1,\n",
    "                          skipinitialspace=False,\n",
    "                          names=['IncidntNum', 'Category', 'Descript', 'DayOfWeek', 'Date', 'Time',\n",
    "                                'PdDistrict', 'Resolution', 'Address', 'X', 'Y', 'Location', 'PdId'])\n",
    "crime_data = crime_data[ ~crime_data['PdDistrict'].isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Time\n",
      "Done Date\n",
      "Done PD District\n",
      "Done Day of Week\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Time\n",
    "crime_data_timeMin = [((int(i.split(':')[0])*60) + int(i.split(':')[1])) for i in crime_data['Time']]\n",
    "crime_data['Time in Min'] = crime_data_timeMin\n",
    "print(\"Done Time\")\n",
    "\n",
    "#Date\n",
    "crime_data_date = [i.split()[0] for i in crime_data['Date']]\n",
    "crime_data_dateDays = [ ((int(i.split('/')[0])-1)*30.4167) + (int(i.split('/')[1])) for i in crime_data_date]\n",
    "crime_data['Date in Days'] = crime_data_dateDays\n",
    "print(\"Done Date\")\n",
    "\n",
    "#PD District\n",
    "District_Parse = list(set([i[0] for i in crime_data[['PdDistrict']].values]))\n",
    "crime_data_District = [np.array([0 if District_Parse.index(d)!=i else\\\n",
    " 1 for (i,p) in enumerate(District_Parse)]) for d in\\\n",
    "crime_data[['PdDistrict']].values]\n",
    "\n",
    "crime_data['One Hot Encoding PdDist'] = crime_data_District\n",
    "print(\"Done PD District\")\n",
    "\n",
    "#Day of week\n",
    "Day_Parse = list(set([i[0] for i in crime_data[['DayOfWeek']].values]))\n",
    "crime_data_Day = [np.array([0 if Day_Parse.index(d)!=i else 1 for\\\n",
    "(i,p) in enumerate(Day_Parse)]) for d in crime_data[['DayOfWeek']]\\\n",
    ".values]\n",
    "\n",
    "crime_data['One Hot Encoding DayOfWeek'] = crime_data_Day\n",
    "\n",
    "print(\"Done Day of Week\")\n",
    "\n",
    "#Category\n",
    "Category_Parse = list(set([i[0] for i in crime_data[['Category']].values]))\n",
    "crime_data_Category = [np.array([0 if Category_Parse.index(d)!=i\\\n",
    "else 1 for (i,p) in enumerate(Category_Parse)]) for d in\\\n",
    "crime_data[['Category']].values]\n",
    "\n",
    "crime_data['One Hot Encoding Category'] = crime_data_Category\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.22398580e+02   3.77920266e+01   1.23000000e+03 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]\n",
      " [ -1.22406412e+02   3.77802525e+01   6.00000000e+01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [ -1.22407878e+02   3.77859680e+01   8.50000000e+02 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [ -1.22424451e+02   3.77671836e+01   1.95000000e+02 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [ -1.22468171e+02   3.77437320e+01   7.20000000e+02 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [ -1.22431046e+02   3.77830296e+01   1.32000000e+03 ...,   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00]]\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def split_sets(dataframe, train_p):\n",
    "    \"\"\"\n",
    "    Returns 2 lists of the form needed to use the KNN class using the San Francisco Crime dataset\n",
    "    -- The function uses x and y coordinate data for graphing and the type of crime as our labels.\n",
    "    **The dataframe passed can be subset to go by location to see how KNN works on each \"area\"\n",
    "    \"\"\"\n",
    "    assert(train_p < 1) # Make sure that p is a percentage\n",
    "    assert(train_p > 0) # Make sure that p is non-negative\n",
    "    \n",
    "    # Split dataframe into training and test/prediction sets\n",
    "    train_count = int(dataframe.shape[0] * train_p)\n",
    "    predict_count = int(dataframe.shape[0] * (1 - train_p))\n",
    "    train_count_Y = int(dataframe.shape[0] * train_p)\n",
    "    predict_count_Y = int(dataframe.shape[0] * (1 - train_p))\n",
    "    \n",
    "    \n",
    "    tmp_list = dataframe.values[:]\n",
    "    np.random.shuffle(tmp_list) # Shuffle the rows\n",
    "    train_list = tmp_list[0:train_count] # Take the first train_p percentage for the training data\n",
    "    predict_list = tmp_list[train_count:] # The rest go to predict data\n",
    "    \n",
    "\n",
    "    rtn_train = [[i[9], i[10], i[13], i[14], *i[15], *i[16]] for i in train_list]\n",
    "    rtn_predict = [[i[9], i[10], i[13], i[14], *i[15], *i[16]]for i in predict_list]\n",
    "    \n",
    "    rtn_train_Y = [i[17] for i in train_list]\n",
    "    rtn_predict_Y = [ i[17] for i in predict_list]\n",
    "    \n",
    "    return rtn_train, rtn_predict, rtn_train_Y, rtn_predict_Y\n",
    "\n",
    "\n",
    "train_NN1, predict_NN1, train_NN1_Y, predict_NN1_Y = split_sets(crime_data, .3)\n",
    "\n",
    "train_NN = np.array(train_NN1)\n",
    "train_NN_Y = np.array(train_NN1_Y)\n",
    "\n",
    "print(train_NN)\n",
    "print(train_NN_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import NN\n",
    "import importlib # needed to reload a module\n",
    "#importlib.reload(nn) # reload to get the new defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 2692.35254157\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "parse_crimes = list(set([i[0] for i in crime_data[['Category']].values]))\n",
    "\n",
    "test = NN(21, 2,2,  .1, True, len(parse_crimes))\n",
    "test.reset()\n",
    "test.train_rounds(train_NN[:1000], train_NN_Y[:1000], 1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 869.445625926\n"
     ]
    }
   ],
   "source": [
    "test.train_rounds(train_NN[:1000], train_NN_Y[:1000], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_rounds(train_NN[:1000], train_NN_Y[:1000], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_rounds(train_NN[:1000], train_NN_Y[:1000], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_rounds(train_NN[:1000], train_NN_Y[:1000], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_rounds(train_NN[:1000], train_NN_Y[:1000], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_rounds(train_NN[:1000], train_NN_Y[:1000], 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_rounds(train_NN[:1000], train_NN_Y[:1000], 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
